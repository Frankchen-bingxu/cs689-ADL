{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Process an image that we can pass to our networks.\n",
    "\"\"\"\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "def process_image(image, target_shape):\n",
    "    \"\"\"Given an image, process it and return the array.\"\"\"\n",
    "    # Load the image.\n",
    "    h, w, _ = target_shape\n",
    "    image = load_img(image, target_size=(h, w))\n",
    "\n",
    "    # Turn it into numpy, normalize and return.\n",
    "    img_arr = img_to_array(image)\n",
    "    x = (img_arr / 255.).astype(np.float32)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class for managing our data.\n",
    "\"\"\"\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import operator\n",
    "from keras.utils import np_utils\n",
    "\n",
    "class DataSet():\n",
    "\n",
    "    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n",
    "        \"\"\"Constructor.\n",
    "        seq_length = (int) the number of frames to consider\n",
    "        class_limit = (int) number of classes to limit the data to.\n",
    "            None = no limit.\n",
    "        \"\"\"\n",
    "        self.seq_length = seq_length\n",
    "        self.class_limit = class_limit\n",
    "        self.sequence_path = './data/sequences/'\n",
    "        self.max_frames = 300  # max number of frames a video can have for us to use it\n",
    "\n",
    "        # Get the data.\n",
    "        self.data = self.get_data()\n",
    "\n",
    "        # Get the classes.\n",
    "        self.classes = self.get_classes()\n",
    "\n",
    "        # Now do some minor data cleaning.\n",
    "        self.data = self.clean_data()\n",
    "\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data():\n",
    "        \"\"\"Load our data from file.\"\"\"\n",
    "        with open('./data/data_file.csv', 'r') as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            data = list(reader)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"Limit samples to greater than the sequence length and fewer\n",
    "        than N frames. Also limit it to classes we want to use.\"\"\"\n",
    "        data_clean = []\n",
    "        for item in self.data:\n",
    "            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n",
    "                    and item[1] in self.classes:\n",
    "                data_clean.append(item)\n",
    "\n",
    "        return data_clean\n",
    "\n",
    "    def get_classes(self):\n",
    "        \"\"\"Extract the classes from our data. If we want to limit them,\n",
    "        only return the classes we need.\"\"\"\n",
    "        classes = []\n",
    "        for item in self.data:\n",
    "            if item[1] not in classes:\n",
    "                classes.append(item[1])\n",
    "\n",
    "        # Sort them.\n",
    "        classes = sorted(classes)\n",
    "\n",
    "        # Return.\n",
    "        if self.class_limit is not None:\n",
    "            return classes[:self.class_limit]\n",
    "        else:\n",
    "            return classes\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        \"\"\"Given a class as a string, return its number in the classes\n",
    "        list. This lets us encode and one-hot it for training.\"\"\"\n",
    "        # Encode it first.\n",
    "        label_encoded = self.classes.index(class_str)\n",
    "\n",
    "        # Now one-hot it.\n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.classes))\n",
    "        label_hot = label_hot[0]  # just get a single row\n",
    "\n",
    "        return label_hot\n",
    "\n",
    "    def split_train_test(self):\n",
    "        \"\"\"Split the data into train and test groups.\"\"\"\n",
    "        train = []\n",
    "        test = []\n",
    "        for item in self.data:\n",
    "            if item[0] == 'train':\n",
    "                train.append(item)\n",
    "            else:\n",
    "                test.append(item)\n",
    "        return train, test\n",
    "\n",
    "    def get_all_sequences_in_memory(self, batch_Size, train_test, data_type, concat=False):\n",
    "        \"\"\"\n",
    "        This is a mirror of our generator, but attempts to load everything into\n",
    "        memory so we can train way faster.\n",
    "        \"\"\"\n",
    "        # Get the right dataset.\n",
    "        train, test = self.split_train_test()\n",
    "        data = train if train_test == 'train' else test\n",
    "\n",
    "        print(\"Getting %s data with %d samples.\" % (train_test, len(data)))\n",
    "\n",
    "        X, y = [], []\n",
    "        for row in data:\n",
    "\n",
    "            sequence = self.get_extracted_sequence(data_type, row)\n",
    "\n",
    "            if sequence is None:\n",
    "                print(\"Can't find sequence. Did you generate them?\")\n",
    "                raise\n",
    "\n",
    "            if concat:\n",
    "                # We want to pass the sequence back as a single array. This\n",
    "                # is used to pass into a CNN or MLP, rather than an RNN.\n",
    "                sequence = np.concatenate(sequence).ravel()\n",
    "\n",
    "            X.append(sequence)\n",
    "            y.append(self.get_class_one_hot(row[1]))\n",
    "\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def frame_generator(self, batch_size, train_test, data_type, concat=False):\n",
    "        \"\"\"Return a generator that we can use to train on. There are\n",
    "        a couple different things we can return:\n",
    "        data_type: 'features', 'images'\n",
    "        \"\"\"\n",
    "        # Get the right dataset for the generator.\n",
    "        train, test = self.split_train_test()\n",
    "        data = train if train_test == 'train' else test\n",
    "\n",
    "        print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n",
    "\n",
    "        while 1:\n",
    "            X, y = [], []\n",
    "\n",
    "            # Generate batch_size samples.\n",
    "            for _ in range(batch_size):\n",
    "                # Reset to be safe.\n",
    "                sequence = None\n",
    "\n",
    "                # Get a random sample.\n",
    "                sample = random.choice(data)\n",
    "\n",
    "                # Check to see if we've already saved this sequence.\n",
    "                if data_type is \"images\":\n",
    "                    # Get and resample frames.\n",
    "                    frames = self.get_frames_for_sample(sample)\n",
    "                    frames = self.rescale_list(frames, self.seq_length)\n",
    "\n",
    "                    # Build the image sequence\n",
    "                    sequence = self.build_image_sequence(frames)\n",
    "                else:\n",
    "                    # Get the sequence from disk.\n",
    "                    sequence = self.get_extracted_sequence(data_type, sample)\n",
    "\n",
    "                if sequence is None:\n",
    "                    print(\"Can't find sequence. Did you generate them?\")\n",
    "                    sys.exit()  # TODO this should raise\n",
    "\n",
    "                if concat:\n",
    "                    # We want to pass the sequence back as a single array. This\n",
    "                    # is used to pass into an MLP rather than an RNN.\n",
    "                    sequence = np.concatenate(sequence).ravel()\n",
    "\n",
    "                X.append(sequence)\n",
    "                y.append(self.get_class_one_hot(sample[1]))\n",
    "\n",
    "            yield np.array(X), np.array(y)\n",
    "\n",
    "    def build_image_sequence(self, frames):\n",
    "        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n",
    "        return [process_image(x, self.image_shape) for x in frames]\n",
    "\n",
    "    def get_extracted_sequence(self, data_type, sample):\n",
    "        \"\"\"Get the saved extracted features.\"\"\"\n",
    "        filename = sample[2]\n",
    "        path = self.sequence_path + filename + '-' + str(self.seq_length) + \\\n",
    "            '-' + data_type + '.txt'\n",
    "        if os.path.isfile(path):\n",
    "            # Use a dataframe/read_csv for speed increase over numpy.\n",
    "            features = pd.read_csv(path, sep=\" \", header=None)\n",
    "            return features.values\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_frames_for_sample(sample):\n",
    "        \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
    "        filenames.\"\"\"\n",
    "        path = './data/' + sample[0] + '/' + sample[1] + '/'\n",
    "        filename = sample[2]\n",
    "        images = sorted(glob.glob(path + filename + '*jpg'))\n",
    "        return images\n",
    "\n",
    "    @staticmethod\n",
    "    def get_filename_from_image(filename):\n",
    "        parts = filename.split('/')\n",
    "        return parts[-1].replace('.jpg', '')\n",
    "\n",
    "    @staticmethod\n",
    "    def rescale_list(input_list, size):\n",
    "        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n",
    "        if we want a list of size 5 and we have a list of size 25, return a new\n",
    "        list of size five which is every 5th element of the origina list.\"\"\"\n",
    "        assert len(input_list) >= size\n",
    "\n",
    "        # Get the number to skip between iterations.\n",
    "        skip = len(input_list) // size\n",
    "\n",
    "        # Build our new output.\n",
    "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
    "\n",
    "        # Cut off the last one if needed.\n",
    "        return output[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0320 10:21:22.876157 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0320 10:21:22.878096 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0320 10:21:22.881305 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0320 10:21:22.984184 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0320 10:21:22.984918 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0320 10:21:24.228347 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0320 10:21:24.437834 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0320 10:21:25.010606 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 93s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0320 10:23:16.581518 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1788425 images belonging to 101 classes.\n",
      "Found 697865 images belonging to 101 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0320 10:25:52.954219 140420457068288 deprecation.py:323] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Top layers.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 129s 1s/step - loss: 4.3240 - acc: 0.1206 - val_loss: 3.4656 - val_acc: 0.2469\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 119s 1s/step - loss: 3.1991 - acc: 0.2803 - val_loss: 2.7902 - val_acc: 0.3625\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 112s 1s/step - loss: 2.6009 - acc: 0.3888 - val_loss: 2.6405 - val_acc: 0.3750\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 112s 1s/step - loss: 2.2281 - acc: 0.4497 - val_loss: 2.1640 - val_acc: 0.4813\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 121s 1s/step - loss: 1.9926 - acc: 0.5000 - val_loss: 2.4973 - val_acc: 0.4500\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 118s 1s/step - loss: 1.8702 - acc: 0.5234 - val_loss: 2.6600 - val_acc: 0.3906\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 117s 1s/step - loss: 1.7188 - acc: 0.5506 - val_loss: 2.7552 - val_acc: 0.4125\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 126s 1s/step - loss: 1.6635 - acc: 0.5634 - val_loss: 2.8425 - val_acc: 0.4094\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 118s 1s/step - loss: 1.5093 - acc: 0.6031 - val_loss: 2.7842 - val_acc: 0.4219\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 122s 1s/step - loss: 1.4795 - acc: 0.6153 - val_loss: 2.6464 - val_acc: 0.4344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0320 10:45:50.528054 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0320 10:45:50.528777 140420457068288 deprecation_wrapper.py:119] From /usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 111s 1s/step - loss: 1.1543 - acc: 0.6956 - top_k_categorical_accuracy: 0.8906 - val_loss: 1.9003 - val_acc: 0.4969 - val_top_k_categorical_accuracy: 0.7875\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.93799 to 1.90033, saving model to ./data/checkpoint/inception.002-1.90.hdf5\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 117s 1s/step - loss: 1.0688 - acc: 0.7238 - top_k_categorical_accuracy: 0.9047 - val_loss: 1.7390 - val_acc: 0.5594 - val_top_k_categorical_accuracy: 0.7937\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.90033 to 1.73900, saving model to ./data/checkpoint/inception.003-1.74.hdf5\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 121s 1s/step - loss: 1.0617 - acc: 0.7147 - top_k_categorical_accuracy: 0.9028 - val_loss: 1.7039 - val_acc: 0.5500 - val_top_k_categorical_accuracy: 0.8250\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.73900 to 1.70393, saving model to ./data/checkpoint/inception.004-1.70.hdf5\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.9923 - acc: 0.7297 - top_k_categorical_accuracy: 0.9200 - val_loss: 1.7982 - val_acc: 0.5094 - val_top_k_categorical_accuracy: 0.7906\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.70393\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 123s 1s/step - loss: 0.9473 - acc: 0.7453 - top_k_categorical_accuracy: 0.9219 - val_loss: 1.7673 - val_acc: 0.5375 - val_top_k_categorical_accuracy: 0.8219\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.70393\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.9138 - acc: 0.7603 - top_k_categorical_accuracy: 0.9303 - val_loss: 1.9087 - val_acc: 0.5125 - val_top_k_categorical_accuracy: 0.7937\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.70393\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.9064 - acc: 0.7603 - top_k_categorical_accuracy: 0.9316 - val_loss: 1.6140 - val_acc: 0.5938 - val_top_k_categorical_accuracy: 0.8313\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.70393 to 1.61399, saving model to ./data/checkpoint/inception.008-1.61.hdf5\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.8907 - acc: 0.7619 - top_k_categorical_accuracy: 0.9278 - val_loss: 1.7998 - val_acc: 0.5312 - val_top_k_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.61399\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.8697 - acc: 0.7706 - top_k_categorical_accuracy: 0.9300 - val_loss: 1.5810 - val_acc: 0.5687 - val_top_k_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.61399 to 1.58097, saving model to ./data/checkpoint/inception.010-1.58.hdf5\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 116s 1s/step - loss: 0.8569 - acc: 0.7728 - top_k_categorical_accuracy: 0.9378 - val_loss: 1.6222 - val_acc: 0.5750 - val_top_k_categorical_accuracy: 0.8594\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.58097\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.8298 - acc: 0.7762 - top_k_categorical_accuracy: 0.9409 - val_loss: 1.4500 - val_acc: 0.6094 - val_top_k_categorical_accuracy: 0.8656\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.58097 to 1.44998, saving model to ./data/checkpoint/inception.012-1.45.hdf5\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.8204 - acc: 0.7778 - top_k_categorical_accuracy: 0.9431 - val_loss: 1.5973 - val_acc: 0.5844 - val_top_k_categorical_accuracy: 0.8250\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.44998\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.7736 - acc: 0.7916 - top_k_categorical_accuracy: 0.9463 - val_loss: 1.7587 - val_acc: 0.5406 - val_top_k_categorical_accuracy: 0.8156\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.44998\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.7711 - acc: 0.7959 - top_k_categorical_accuracy: 0.9419 - val_loss: 1.6309 - val_acc: 0.5813 - val_top_k_categorical_accuracy: 0.8219\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.44998\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.7462 - acc: 0.7966 - top_k_categorical_accuracy: 0.9463 - val_loss: 1.5667 - val_acc: 0.5687 - val_top_k_categorical_accuracy: 0.8844\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.44998\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.7247 - acc: 0.8103 - top_k_categorical_accuracy: 0.9509 - val_loss: 1.7401 - val_acc: 0.5406 - val_top_k_categorical_accuracy: 0.8125\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.44998\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.7125 - acc: 0.8166 - top_k_categorical_accuracy: 0.9559 - val_loss: 1.4960 - val_acc: 0.6219 - val_top_k_categorical_accuracy: 0.8531\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.44998\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.6827 - acc: 0.8137 - top_k_categorical_accuracy: 0.9578 - val_loss: 1.6554 - val_acc: 0.5312 - val_top_k_categorical_accuracy: 0.8344\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.44998\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.6889 - acc: 0.8128 - top_k_categorical_accuracy: 0.9513 - val_loss: 1.4506 - val_acc: 0.5844 - val_top_k_categorical_accuracy: 0.8812\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.44998\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.7118 - acc: 0.8091 - top_k_categorical_accuracy: 0.9506 - val_loss: 1.7775 - val_acc: 0.5875 - val_top_k_categorical_accuracy: 0.7906\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.44998\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.6772 - acc: 0.8231 - top_k_categorical_accuracy: 0.9550 - val_loss: 1.4844 - val_acc: 0.5969 - val_top_k_categorical_accuracy: 0.8656\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.44998\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train on images split into directories. This assumes we've split\n",
    "our videos into frames and moved them to their respective folders.\n",
    "Use keras 2+ and tensorflow 1+\n",
    "Based on:\n",
    "https://keras.io/preprocessing/image/\n",
    "and\n",
    "https://keras.io/applications/\n",
    "\"\"\"\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "\n",
    "data = DataSet()\n",
    "\n",
    "# Helper: Save the min val_loss model in each epoch.\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='./data/checkpoint/inception.{epoch:03d}-{val_loss:.2f}.hdf5',\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "# Helper: Stop when we stop learning.\n",
    "# patience: number of epochs with no improvement after which training will be stopped.\n",
    "early_stopper = EarlyStopping(patience=10)\n",
    "\n",
    "# Helper: TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='./data/logs/')\n",
    "\n",
    "def get_generators():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=10.,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        './data/train/',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        classes=data.classes,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        './data/test/',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        classes=data.classes,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "def get_model(weights='imagenet'):\n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights=weights, include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 2 classes\n",
    "    predictions = Dense(len(data.classes), activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def fine_tune_inception_layer(model):\n",
    "    \"\"\"After we fine-tune the dense layers, train deeper.\"\"\"\n",
    "    # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "    # the first 172 layers and unfreeze the rest:\n",
    "    for layer in model.layers[:172]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[172:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # we need to recompile the model for these modifications to take effect\n",
    "    # we use SGD with a low learning rate\n",
    "    model.compile(\n",
    "        optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, nb_epoch, generators, callbacks=[]):\n",
    "    train_generator, validation_generator = generators\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10,\n",
    "        epochs=nb_epoch,\n",
    "        callbacks=callbacks)\n",
    "    return model\n",
    "\n",
    "def main(weights_file):\n",
    "\n",
    "    model = get_model()\n",
    "    generators = get_generators()\n",
    "\n",
    "    if weights_file is None:\n",
    "        print(\"Training Top layers.\")\n",
    "        model = train_model(model, 10, generators)\n",
    "    else:\n",
    "        print(\"Loading saved model: %s.\" % weights_file)\n",
    "        model.load_weights(weights_file)\n",
    "\n",
    "    # Get and train the mid layers.\n",
    "    model = fine_tune_inception_layer(model)\n",
    "    model = train_model(model, 1000, generators,\n",
    "                        [checkpointer, early_stopper, tensorboard])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    weights_file = None\n",
    "    main(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 697865 images belonging to 101 classes.\n",
      "[1.6648375314092558, 0.5594262999816582, 0.8258093360234776]\n",
      "['accuracy', 'top_k_categorical_accuracy']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classify test images set through our CNN.\n",
    "Use keras 2+ and tensorflow 1+\n",
    "It takes a long time for hours.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import operator\n",
    "import random\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data = DataSet()\n",
    "def main(nb_images=5):\n",
    "    # CNN model evaluate\n",
    "\n",
    "    test_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "    test_data_num = 697865 #the number of test images\n",
    "    batch_size = 32\n",
    "    test_generator = test_data_gen.flow_from_directory('./data/test/', target_size=(299, 299),\n",
    "                                                       batch_size=batch_size, classes=data.classes,\n",
    "                                                       class_mode='categorical')\n",
    "    # load the trained model that has been saved in CNN_train_UCF101.py, your model name maybe is not the same as follow\n",
    "    model = load_model('data/checkpoint/inception.012-1.45.hdf5')\n",
    "    results = model.evaluate_generator(generator=test_generator, steps=test_data_num // batch_size)\n",
    "    print(results)\n",
    "    print(model.metrics)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "./data/test/BandMarching/v_BandMarching_g02_c07-0008.jpg\n",
      "BandMarching: 0.95\n",
      "Drumming: 0.01\n",
      "BenchPress: 0.01\n",
      "PlayingDaf: 0.00\n",
      "Lunges: 0.00\n",
      "--------------------------------------------------------------------------------\n",
      "./data/test/SalsaSpin/v_SalsaSpin_g03_c02-0112.jpg\n",
      "HulaHoop: 0.28\n",
      "Nunchucks: 0.13\n",
      "TennisSwing: 0.08\n",
      "GolfSwing: 0.06\n",
      "SalsaSpin: 0.05\n",
      "--------------------------------------------------------------------------------\n",
      "./data/test/WallPushups/v_WallPushups_g02_c02-0055.jpg\n",
      "Nunchucks: 0.30\n",
      "MoppingFloor: 0.14\n",
      "WallPushups: 0.09\n",
      "JumpingJack: 0.07\n",
      "JugglingBalls: 0.05\n",
      "--------------------------------------------------------------------------------\n",
      "./data/test/PlayingDaf/v_PlayingDaf_g01_c02-0066.jpg\n",
      "PlayingDaf: 0.28\n",
      "YoYo: 0.21\n",
      "PlayingFlute: 0.08\n",
      "JugglingBalls: 0.07\n",
      "PlayingGuitar: 0.07\n",
      "--------------------------------------------------------------------------------\n",
      "./data/test/Rowing/v_Rowing_g01_c01-0306.jpg\n",
      "Rowing: 0.93\n",
      "Skijet: 0.01\n",
      "CliffDiving: 0.01\n",
      "Surfing: 0.01\n",
      "Skiing: 0.01\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classify a few images through our CNN.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import operator\n",
    "import random\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "\n",
    "def main(nb_images=5):\n",
    "    \"\"\"Spot-check `nb_images` images.\"\"\"\n",
    "    data = DataSet()\n",
    "    model = load_model('data/checkpoint/inception.012-1.45.hdf5') #replaced by your model name\n",
    "\n",
    "    # Get all our test images.\n",
    "    images = glob.glob('./data/test/**/*.jpg')\n",
    "\n",
    "    for _ in range(nb_images):\n",
    "        print('-'*80)\n",
    "        # Get a random row.\n",
    "        sample = random.randint(0, len(images) - 1)\n",
    "        image = images[sample]\n",
    "\n",
    "        # Turn the image into an array.\n",
    "        print(image)\n",
    "        image_arr = process_image(image, (299, 299, 3))\n",
    "        image_arr = np.expand_dims(image_arr, axis=0)\n",
    "\n",
    "        # Predict.\n",
    "        predictions = model.predict(image_arr)\n",
    "\n",
    "        # Show how much we think it's each one.\n",
    "        label_predictions = {}\n",
    "        for i, label in enumerate(data.classes):\n",
    "            label_predictions[label] = predictions[0][i]\n",
    "\n",
    "        sorted_lps = sorted(label_predictions.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        \n",
    "        for i, class_prediction in enumerate(sorted_lps):\n",
    "            # Just get the top five.\n",
    "            if i > 4:\n",
    "                break\n",
    "            print(\"%s: %.2f\" % (class_prediction[0], class_prediction[1]))\n",
    "            i += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
